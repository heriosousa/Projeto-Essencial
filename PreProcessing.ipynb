{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating datasets for gene prediction experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import modelo as m\n",
    "import pandas as pd\n",
    "import Bio.KEGG.REST as rkg\n",
    "import Bio.KEGG.Enzyme as ex\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. coli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from KEGG PATHWAY database. Sat Apr 28 15:13:05 2018\n",
      "Building graphs.\n"
     ]
    }
   ],
   "source": [
    "eco = m.get_network(\"eco\", opt=\"eco\")\n",
    "eco.grafo = eco.grafo.to_undirected()\n",
    "eco_nodes = list(eco.grafo.nodes())\n",
    "eco_nodes.remove('undefined')\n",
    "orf_queries = dict()\n",
    "\n",
    "for i in range(len(eco_nodes)):\n",
    "    gene = rkg.kegg_get(eco_nodes[i])\n",
    "    tmp = ex.read(gene)\n",
    "    if eco_nodes[i].startswith(\"eco:\"):\n",
    "        orf_queries[eco_nodes[i]] = tmp.name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Centralities\n",
    "close_cent = nx.closeness_centrality(eco.grafo)\n",
    "bet_cent = nx.betweenness_centrality(eco.grafo)\n",
    "eigen_cent = nx.eigenvector_centrality(eco.grafo)\n",
    "load_cent = nx.load_centrality(eco.grafo)\n",
    "deg_cent = nx.degree_centrality(eco.grafo)\n",
    "lreach_cent = {k:nx.local_reaching_centrality(eco.grafo, k) for k in eco.grafo.nodes()}\n",
    "\n",
    "n = len(eco.grafo) - 1 #normalizing harmonic_centrality\n",
    "harm_cent = {k:(v/n) for k,v in nx.harmonic_centrality(eco.grafo).items()}\n",
    "\n",
    "n = nx.estrada_index(eco.grafo) #normalizing subgraph_centrality\n",
    "sub_cent = {k:(v/n) for k,v in nx.subgraph_centrality(eco.grafo).items()}\n",
    "\n",
    "#Other features\n",
    "cco = nx.clustering(eco.grafo)\n",
    "pagerank = nx.pagerank(eco.grafo)\n",
    "hits = nx.hits(eco.grafo)\n",
    "ind_set = {k:len(nx.maximal_independent_set(eco.grafo, [k])) for k in eco.grafo.nodes()} #to be normalized later\n",
    "damage = m.damage_lemke(eco.grafo) #to be normalized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_eco = {v:k for k, v in orf_queries.items()}\n",
    "table = pd.read_table(\"data/EcoliNetData.dat\") #Generated in a previous step (another notebook)\n",
    "node2rem = []\n",
    "for j in eco.grafo.nodes():\n",
    "    if orf_queries.get(j,None) == None:\n",
    "        node2rem.append(j)\n",
    "eco.grafo.remove_nodes_from(node2rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = []\n",
    "#Nodes of unknown essentiality are discarded\n",
    "for i,j in zip(table[\"Feature/Product\"], table[\"Class(1:essential 2:noessential)\"]):\n",
    "    tmp = nodes_eco.get(i,None)\n",
    "    if tmp != None:\n",
    "        aux.append([tmp, eigen_cent[tmp], close_cent[tmp], bet_cent[tmp], load_cent[tmp], harm_cent[tmp], lreach_cent[tmp], \n",
    "                     sub_cent[tmp], deg_cent[tmp], cco[tmp], pagerank[tmp], hits[0][tmp], ind_set[tmp], damage[tmp], j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(aux, columns = [\"ec\", \"eigenvector_centrality\", \"closeness_centrality\", \"betweenness_centrality\",\n",
    "                                    \"load_centrality\", \"harmonic_centrality\", \"local_reach_centrality\", \"subgraph_centrality\",\n",
    "                                    \"degree_centrality\", \"clustering_coefficient\", \"pagerank\", \"hits\", \"ind_set_maximal\", \n",
    "                                    \"damage\", \"class\"])\n",
    "#Normalizing remaining features\n",
    "data['ind_set_maximal'] = data['ind_set_maximal'] / max(data['ind_set_maximal'])\n",
    "data['damage'] = data['damage'] / max(data['damage'])\n",
    "data = data[data['degree_centrality'] != 0.0] #Removing isolates\n",
    "data.to_csv('data/ecoli.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M. genitalium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from KEGG PATHWAY database. Sat Apr 28 15:41:01 2018\n",
      "Building graphs.\n"
     ]
    }
   ],
   "source": [
    "mge = m.get_network(\"mge\", opt=\"mge\")\n",
    "mge.grafo = mge.grafo.to_undirected()\n",
    "mge_nodes = list(mge.grafo.nodes())\n",
    "mge_nodes.remove('undefined')\n",
    "orf_queries = dict()\n",
    "\n",
    "for i in range(len(mge_nodes)):\n",
    "    gene = rkg.kegg_get(mge_nodes[i])\n",
    "    tmp = ex.read(gene)\n",
    "    if mge_nodes[i].startswith(\"mge:\") and tmp.name != []:\n",
    "        orf_queries[mge_nodes[i]] = tmp.name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Centralities\n",
    "close_cent = nx.closeness_centrality(mge.grafo)\n",
    "bet_cent = nx.betweenness_centrality(mge.grafo)\n",
    "eigen_cent = nx.eigenvector_centrality(mge.grafo)\n",
    "load_cent = nx.load_centrality(mge.grafo)\n",
    "deg_cent = nx.degree_centrality(mge.grafo)\n",
    "lreach_cent = {k:nx.local_reaching_centrality(mge.grafo, k) for k in mge.grafo.nodes()}\n",
    "\n",
    "n = len(mge.grafo) - 1 #normalizing harmonic_centrality\n",
    "harm_cent = {k:(v/n) for k,v in nx.harmonic_centrality(mge.grafo).items()}\n",
    "\n",
    "n = nx.estrada_index(mge.grafo) #normalizing subgraph_centrality\n",
    "sub_cent = {k:(v/n) for k,v in nx.subgraph_centrality(mge.grafo).items()}\n",
    "\n",
    "#Other features\n",
    "cco = nx.clustering(mge.grafo)\n",
    "pagerank = nx.pagerank(mge.grafo)\n",
    "hits = nx.hits(mge.grafo)\n",
    "ind_set = {k:len(nx.maximal_independent_set(mge.grafo, [k])) for k in mge.grafo.nodes()} #to be normalized later\n",
    "damage = m.damage_lemke(mge.grafo) #to be normalized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_mge = {v:k for k,v in orf_queries.items()}\n",
    "table = pd.read_table(\"data/MgenitaliumNetData.dat\") #Generated in a previous step (another notebook)\n",
    "node2rem = []\n",
    "for j in mge.grafo.nodes():\n",
    "    if orf_queries.get(j,None) == None:\n",
    "        node2rem.append(j)\n",
    "mge.grafo.remove_nodes_from(node2rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = []\n",
    "#Nodes of unknown essentiality are discarded\n",
    "for i,j in zip(table[\"Feature/Product\"], table[\"Class(1:essential 2:noessential)\"]):\n",
    "    tmp = nodes_mge.get(i,None)\n",
    "    if tmp != None:\n",
    "        aux.append([tmp, eigen_cent[tmp], close_cent[tmp], bet_cent[tmp], load_cent[tmp], harm_cent[tmp], lreach_cent[tmp], \n",
    "                     sub_cent[tmp], deg_cent[tmp], cco[tmp], pagerank[tmp], hits[0][tmp], ind_set[tmp], damage[tmp], j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(aux, columns = [\"ec\", \"eigenvector_centrality\", \"closeness_centrality\", \"betweenness_centrality\",\n",
    "                                    \"load_centrality\", \"harmonic_centrality\", \"local_reach_centrality\", \"subgraph_centrality\",\n",
    "                                    \"degree_centrality\", \"clustering_coefficient\", \"pagerank\", \"hits\", \"ind_set_maximal\", \n",
    "                                    \"damage\", \"class\"])\n",
    "#Normalizing remaining features\n",
    "data['ind_set_maximal'] = data['ind_set_maximal'] / max(data['ind_set_maximal'])\n",
    "data['damage'] = data['damage'] / max(data['damage'])\n",
    "data = data[data['degree_centrality'] != 0.0] #Removing isolates\n",
    "data.to_csv('data/mgenitalium.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P. aeruginosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from KEGG PATHWAY database. Sat Apr 28 15:48:00 2018\n",
      "Building graphs.\n"
     ]
    }
   ],
   "source": [
    "pae = m.get_network(\"pae\", opt=\"pae\")\n",
    "pae.grafo = pae.grafo.to_undirected()\n",
    "pae_nodes = list(pae.grafo.nodes())\n",
    "pae_nodes.remove('undefined')\n",
    "orf_queries = dict()\n",
    "\n",
    "for i in range(len(pae_nodes)):\n",
    "    gene = rkg.kegg_get(pae_nodes[i])\n",
    "    tmp = ex.read(gene)\n",
    "    if pae_nodes[i].startswith(\"pae:\") and tmp.name != []:\n",
    "        orf_queries[pae_nodes[i]] = tmp.name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Centralities\n",
    "close_cent = nx.closeness_centrality(pae.grafo)\n",
    "bet_cent = nx.betweenness_centrality(pae.grafo)\n",
    "eigen_cent = nx.eigenvector_centrality(pae.grafo)\n",
    "load_cent = nx.load_centrality(pae.grafo)\n",
    "deg_cent = nx.degree_centrality(pae.grafo)\n",
    "lreach_cent = {k:nx.local_reaching_centrality(pae.grafo, k) for k in pae.grafo.nodes()}\n",
    "\n",
    "n = len(pae.grafo) - 1 #normalizing harmonic_centrality\n",
    "harm_cent = {k:(v/n) for k,v in nx.harmonic_centrality(pae.grafo).items()}\n",
    "\n",
    "n = nx.estrada_index(pae.grafo) #normalizing subgraph_centrality\n",
    "sub_cent = {k:(v/n) for k,v in nx.subgraph_centrality(pae.grafo).items()}\n",
    "\n",
    "#Other features\n",
    "cco = nx.clustering(pae.grafo)\n",
    "pagerank = nx.pagerank(pae.grafo)\n",
    "hits = nx.hits(pae.grafo)\n",
    "ind_set = {k:len(nx.maximal_independent_set(pae.grafo, [k])) for k in pae.grafo.nodes()} #to be normalized later\n",
    "damage = m.damage_lemke(pae.grafo) #to be normalized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_pae = {v:k for k, v in orf_queries.items()}\n",
    "table = pd.read_table(\"data/PaeruginosaNetData.dat\") #Generated in a previous step (another notebook)\n",
    "node2rem = []\n",
    "for j in pae.grafo.nodes():\n",
    "    if orf_queries.get(j,None) == None:\n",
    "        node2rem.append(j)\n",
    "pae.grafo.remove_nodes_from(node2rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = []\n",
    "#Nodes of unknown essentiality are discarded\n",
    "for i,j in zip(table[\"Feature/Product\"], table[\"Class(1:essential 2:noessential)\"]):\n",
    "    tmp = nodes_pae.get(i,None)\n",
    "    if tmp != None:\n",
    "        aux.append([tmp, eigen_cent[tmp], close_cent[tmp], bet_cent[tmp], load_cent[tmp], harm_cent[tmp], lreach_cent[tmp], \n",
    "                     sub_cent[tmp], deg_cent[tmp], cco[tmp], pagerank[tmp], hits[0][tmp], ind_set[tmp], damage[tmp], j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(aux, columns = [\"ec\", \"eigenvector_centrality\", \"closeness_centrality\", \"betweenness_centrality\",\n",
    "                                    \"load_centrality\", \"harmonic_centrality\", \"local_reach_centrality\", \"subgraph_centrality\",\n",
    "                                    \"degree_centrality\", \"clustering_coefficient\", \"pagerank\", \"hits\", \"ind_set_maximal\", \n",
    "                                    \"damage\", \"class\"])\n",
    "#Normalizing remaining features\n",
    "data['ind_set_maximal'] = data['ind_set_maximal'] / max(data['ind_set_maximal'])\n",
    "data['damage'] = data['damage'] / max(data['damage'])\n",
    "data = data[data['degree_centrality'] != 0.0] #Removing isolates\n",
    "data.to_csv('data/paeruginosa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S. cerevisiae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from KEGG PATHWAY database. Sat Apr 28 16:36:50 2018\n",
      "Building graphs.\n"
     ]
    }
   ],
   "source": [
    "sce = m.get_network(\"sce\", opt=\"sce\")\n",
    "sce.grafo = sce.grafo.to_undirected()\n",
    "sce_nodes = list(sce.grafo.nodes())\n",
    "sce_nodes.remove('undefined')\n",
    "orf_queries = dict()\n",
    "\n",
    "for i in range(len(sce_nodes)):\n",
    "    gene = rkg.kegg_get(sce_nodes[i])\n",
    "    tmp = ex.read(gene)\n",
    "    if sce_nodes[i].startswith(\"sce:\"):\n",
    "        orf_queries[sce_nodes[i]] = sce_nodes[i].split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Centralities\n",
    "close_cent = nx.closeness_centrality(sce.grafo)\n",
    "bet_cent = nx.betweenness_centrality(sce.grafo)\n",
    "eigen_cent = nx.eigenvector_centrality(sce.grafo)\n",
    "load_cent = nx.load_centrality(sce.grafo)\n",
    "deg_cent = nx.degree_centrality(sce.grafo)\n",
    "lreach_cent = {k:nx.local_reaching_centrality(sce.grafo, k) for k in sce.grafo.nodes()}\n",
    "\n",
    "n = len(sce.grafo) - 1 #normalizing harmonic_centrality\n",
    "harm_cent = {k:(v/n) for k,v in nx.harmonic_centrality(sce.grafo).items()}\n",
    "\n",
    "n = nx.estrada_index(sce.grafo) #normalizing subgraph_centrality\n",
    "sub_cent = {k:(v/n) for k,v in nx.subgraph_centrality(sce.grafo).items()}\n",
    "\n",
    "#Other features\n",
    "cco = nx.clustering(sce.grafo)\n",
    "pagerank = nx.pagerank(sce.grafo)\n",
    "hits = nx.hits(sce.grafo)\n",
    "ind_set = {k:len(nx.maximal_independent_set(sce.grafo, [k])) for k in sce.grafo.nodes()} #to be normalized later\n",
    "damage = m.damage_lemke(sce.grafo) #to be normalized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_sce = {v:k for k, v in orf_queries.items()}\n",
    "table = pd.read_table(\"data/ScerevisiaeNetData.dat\") #Generated in a previous step (another notebook)\n",
    "node2rem = []\n",
    "for j in sce.grafo.nodes():\n",
    "    if orf_queries.get(j,None) == None:\n",
    "        node2rem.append(j)\n",
    "sce.grafo.remove_nodes_from(node2rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = []\n",
    "#Nodes of unknown essentiality are discarded\n",
    "for i,j in zip(table[\"Feature/Product\"], table[\"Class(1:essential 2:noessential)\"]):\n",
    "    tmp = nodes_sce.get(i,None)\n",
    "    if tmp != None:\n",
    "        aux.append([tmp, eigen_cent[tmp], close_cent[tmp], bet_cent[tmp], load_cent[tmp], harm_cent[tmp], lreach_cent[tmp], \n",
    "                     sub_cent[tmp], deg_cent[tmp], cco[tmp], pagerank[tmp], hits[0][tmp], ind_set[tmp], damage[tmp], j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(aux, columns = [\"ec\", \"eigenvector_centrality\", \"closeness_centrality\", \"betweenness_centrality\",\n",
    "                                    \"load_centrality\", \"harmonic_centrality\", \"local_reach_centrality\", \"subgraph_centrality\",\n",
    "                                    \"degree_centrality\", \"clustering_coefficient\", \"pagerank\", \"hits\", \"ind_set_maximal\", \n",
    "                                    \"damage\", \"class\"])\n",
    "#Normalizing remaining features\n",
    "data['ind_set_maximal'] = data['ind_set_maximal'] / max(data['ind_set_maximal'])\n",
    "data['damage'] = data['damage'] / max(data['damage'])\n",
    "data = data[data['degree_centrality'] != 0.0] #Removing isolates\n",
    "data.to_csv('data/scerevisiae.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
